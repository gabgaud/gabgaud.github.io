# Laboratoire 3

* * *

## Cr√©ation d'une premi√®re machine virtuelle sous Proxmox

## Pr√©alables

- Avoir un hyperviseur Proxmox pr√™t √† √™tre utilis√©.
- Avoir consult√© la th√©orie en lien avec ce cours.

## Objectifs

- Faire l'installation d'une premi√®re machine virtuelle sous Proxmox

## √âtapes de r√©alisation

Dans ce laboratoire, nous passerons ensemble les diff√©rentes √©tapes n√©cessaires √† la cr√©ation d'une premi√®re machine virtuelle dans Proxmox. Nous analyserons les fen√™tres et les options qui s'offrent √† vous en prenant soin de les d√©cortiquer.

### √âtape 1 - Mise √† jour de l'hyperviseur

Avant de se lancer dans la cr√©ation de notre premi√®re *VM*, nous allons nous assurer que l'hyperviseur est bien √† jour. Dans le volet de gauche, cliquez sur votre n≈ìud, puis dans le panneau central, cliquez sur `Repositories`.

![Repo](../Assets/03/Repo.png)

Vous verrez un avertissement concernant le catalogue de mise √† jour *enterprise*. Ce catalogue de mise √† jour est r√©serv√© aux entreprises qui paient une licence pour l'utilisation de Proxmox. Nous allons donc d√©sactiver ce catalogue en cliquant sur celui-ci, puis sur `Disable`. Faites de m√™me avec le catalogue *ceph-quincy*.

![DisableEnterpriseRepo](../Assets/03/DisableRepoEnterprise.png)

Proxmox vous avisera alors que vous n'avez plus acc√®s √† aucune mise √† jour de l'hyperviseur. Pour r√©gler cela, cliquez sur `Add` puis s√©lectionnez le catalogue `No-Subscription`. Cliquez sur `Reload` pour vous assurez que vos changements ont √©t√© pris en compte.

Cliquez maintenant sur `Updates` (juste au-dessus de `Repositories`). Cliquez sur `Refresh` pour effectuer une v√©rification des mises √† jour et finalement sur `>_ Upgrade` pour lancer le processus de mise √† jour du syst√®me.

![Upgrade](../Assets/03/Upgrade.png)

La console du n≈ìud s'ouvrira automatiquement. Remarquez la commande qui a √©t√© lanc√©e au haut de la fen√™tre.

Que vous lanciez cette commande directement dans la console ou que vous passiez par l'interface graphique, le processus est exactement le m√™me. Appuyez sur <kbd>enter</kbd> pour confirmer l'installation des mises √† jour.

### √âtape 2 - Cr√©ation d'une VM Windows

Dans la barre sup√©rieure de la console de gestion, cliquez sur le bouton `Create VM`.

#### Onglet g√©n√©ral

Dans l'onglet g√©n√©ral, vous aurez acc√®s √† diff√©rents √©l√©ments pour la cr√©ation de votre VM:

- **Node:** Le serveur physique sur lequel cr√©er votre machine virtuelle.

- **VM ID:** C'est un num√©ro unique √† votre machine virtuelle et c'est <u>obligatoire</u>. Ces identifiants commencent √† 100 et ne peuvent √™tre inf√©rieurs √† ce nombre.

- **Name:** Le nom que vous d√©sirez donner √† votre machine.

- **Ressource Pool:** Les *pools* de ressource sont des rassemblements logiques auxquels vous pouvez associer plusieurs *VMs* ou *Containers*. Ce *pool* est ensuite utilis√© principalement pour:
    - Organiser les ressources: Classer les ressources par √©quipe, par projet, par client, etc.
    - Contr√¥ler les acc√®s: Appliquer des *ACLs* √† un pool plut√¥t qu'√† chaque VM individuellement.
    - Administration simplifi√©e: Faciliter la gestion d'un ensemble de ressources li√©es.

- **Options de d√©marrage:** Section o√π vous pouvez d√©terminer certaines options de d√©marrage:
    - Start at boot: D√©termine si la *VM* doit d√©marrer imm√©diatement apr√®s le d√©marrage de l'hyperviseur.
    - Start/Shutdown order: D√©termine quelle *VM* doit d√©marrer et √™tre arr√™t√© en premier, deuxi√®me, etc.
    - Startup Delay: D√©lai, en secondes, que l'hyperviseur doit attendre avant de lancer le d√©marrage automatique de la *VM*.
    - Shutdown Timeout: Temps, en secondes, que l'hyperviseur attendra pour un arr√™t propre avant de forcer l'arr√™t.

:::caution
Les options *Start order* et *Startup delay* ne sont valables que si l'option *Start at boot* est activ√©e.
:::

- **Tags:** Permet tout simplement de cat√©goriser vos machines virtuelles et vos conteneurs.

![CreateGeneral](../Assets/03/CreateGeneral.png)

#### Onglet OS

Dans la fen√™tre OS, vous pourrez s√©lectionner votre ISO d'installation. Dans le cas pr√©sent, l'ISO de Windows 10 22H2. Par d√©faut, l'iso que vous avez t√©l√©charg√© se trouve dans votre stockage nomm√© **Local**. S√©lectionnez-le.

Dans la section *Guest OS* de la fen√™tre, il vous faudra indiquer que vous comptez installer Windows 10. Lorsque ce sera fait, une case suppl√©mentaire fera son apparition. *Add additional drive for VirtIO drivers*. Les *VirtIO drivers* sont des pilotes qui permettent d'effectuer de la paravirtualisation, ce que Windows ne supporte pas toujours nativement. La paravirtualisation permet une meilleure gestion de l'acc√®s au mat√©riel physique. Par exemple, la technique du *ballooning* que le *memory manager* peut effectuer dans l'hyperviseur afin d'optimiser la m√©moire vive est r√©alis√©e gr√¢ce √† un pilote paravirtualis√©.

Pour en conna√Ætre davantage sur les diff√©rences entre une √©mulation de pilote compl√®te et la paravirtualisation, [consultez cette page.](https://developer.ibm.com/articles/l-virtio/)

Pour b√©n√©ficier de pilotes paravirtualis√©s sous Windows, il existe des pilotes libres de droits, disponibles sous un iso t√©l√©chargeable √† partir de [ce lien](https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/archive-virtio/virtio-win-0.1.271-1/virtio-win.iso). Au cours pr√©c√©dent, vous avez appris comment il √©tait possible de t√©l√©charger un fichier iso directement sous Proxmox...√† vous de jouer üòâ

![OngletOS](../Assets/03/OngletOS.png)

#### Onglet Syst√®me

* * *

<span class="green-text">**Carte graphique**</span><br/><br/>

Comme nous avons l'intention d'installer une s√©rie de pilotes paravirtualis√©s pour Windows, autant en profiter. Dans l'onglet suivant, choisissez `VirtIO-GPU` pour la carte graphique. L'acc√®s au processeur graphique en sera am√©lior√©. Vous avez sans doute remarqu√© qu'il existe une panoplie de possibilit√© pour la carte graphique. En voici un petit r√©sum√©:

|**Carte Graphique**|**Type de carte**|**Usage principal**|**Avantages**|**Inconv√©nients**|
|-------------------|-----------------|-------------------|-------------|-----------------|
|**Default**|Standard VGA|Usage g√©n√©ral, minimaliste|Facilit√© d'utilisation et installation automatique|Performances graphiques limit√©es, pas de 3D ni d'acc√©l√©ration|
|**VGA Basique**| VGA Standard|Bureau, applications l√©g√®res et basiques|Large compatibilit√©, simple √† configurer|Pas d'acc√©l√©ration graphique, performances limit√©es|
|**VMware Compatible**|Compatible VMware|Applications avec besoin de compatibilit√© VMware|Compatible avec les outils VMware, bonne compatibilit√©|Limitations graphiques, pas d'acc√©l√©ration 3D|
|**Spice (1 ou plusieurs moniteurs)**|Spice|Utilisation avec plusieurs moniteurs ou environnement graphique de bureau|Support des environnements virtuels multimoniteurs, bonne interaction avec Spice|Moins performant graphiquement que d'autres solutions, d√©pend de Spice|
|**Serial Terminal**|Terminal s√©rie|Acc√®s au terminal en ligne, sans interface graphique|L√©ger, utilis√© pour administration √† distance sans graphique|Pas d'interface graphique, ne supporte pas les applications graphiques|
|**VirtIO-GPU**|Paravirtualis√©|Applications avec besoin d'une acc√©l√©ration l√©g√®re (vid√©os, graphiques l√©gers)|Bonne acc√©l√©ration graphique, l√©ger sur les ressources| Performances 3D limit√©es pour les applications lourdes|
|**VirGL GPU**|GPU partag√© (OpenGL)|Acc√©l√©ration 3D, jeux l√©gers, mod√©lisation 3D|Meilleure performance graphique 3D, bon rendu OpenGL|Configuration plus complexe, n√©cessite un GPU h√¥te compatible|

<span class="green-text">**Machine**</span><br/><br/>

L'option `Machine` devrait plut√¥t se nommer *chipset*, car c'est vraiment ce dont on parle ici. L'option par d√©faut ici n'est pas la plus performante. En effet, le *chipset* **i440fx** en est un vieux. Ce *chipset* √©tait utilis√© sur d‚Äôanciennes cartes m√®res o√π l'on retrouvait principalement des processeurs en architecture x86. C'est tr√®s compatible, mais r√©ellement peu performant avec des syst√®mes consid√©r√©s modernes tels que Windows 10 ou Windows 11.

Le *chipset* **q35** est plus moderne et prend en charge des technologies plus r√©centes telles que le **PCIe** ou m√™me le **USB3**. Il est beaucoup plus adapt√© √† des syst√®mes d'exploitation r√©cents comme Windows 10 & 11.

* * *

<span class="green-text">**Bios**</span><br/><br/>

Les diff√©rences entre le BIOS et le UEFI sont nombreuses. Si vous avez besoin de vous rafraichir la m√©moire, [une section du cours de syst√®mes d'exploitation](../../OS/Windows/16-D√©marrage.md#firmware) explique bien ces diff√©rences. Vous pouvez relire ces sections au besoin.

Dans notre cas, nous opterons pour l'option **UEFI**. J'imagine que vous savez tr√®s bien pourquoi, car vous avez pris soin de relire la section propos√©e ci-dessus... n'est-ce pas ? üòâ

Or, un firmware de type **UEFI** a n√©cessairement besoin d'un espace de stockage. S√©lectionnez tout simplement votre stockage `local-lvm`. L'option `Pre-Enroll Keys` permet de sp√©cifier des cl√©s qui seront ajout√©es au d√©marrage s√©curis√© (*Secure Boot*) pour permettre la validation de certains fichiers de boot ou noyaux non sign√©s ou sign√©s de mani√®re personnalis√©e. Dans le cas o√π nous n'utilisons pas *Secure Boot*, ou si nous n'avons pas de besoins sp√©cifiques de s√©curit√© pour l'environnement de machine virtuelle que nous d√©ployons, cette option peut √™tre ignor√©e.

* * *

<span class="green-text">**SCSI Controller**</span><br/><br/>

L'option `SCSI Controller` pourrait aussi se nommer *Disk Controller*. Plusieurs options s'offrent √† vous, voici comment les distinguer:

|**Contr√¥leur**|**Type de contr√¥leur**|**Caract√©ristiques**|**Avantages**|**Inconv√©nients**|**Utilisation recommand√©e**|
|--------------|----------------------|--------------------|-------------|-----------------|---------------------------|
|**LSI 53C895A**|Contr√¥leur SCSI|Contr√¥leur SCSI classique bas√© sur l'architecture LSI 53C895A. Compatible avec des syst√®mes SCSI.|Bonne compatibilit√© avec les syst√®mes d'exploitation plus anciens|Performances limit√©es par rapport aux contr√¥leurs modernes|Syst√®mes d'exploitation anciens ou pour des configurations SCSI sp√©cifiques|
|**LSI 53C810**|Contr√¥leur SCSI|Ancien contr√¥leur SCSI, utilis√© dans des syst√®mes plus anciens avec des disques durs SCSI traditionnels.|Simple et efficace pour des environnements SCSI classiques|Pas optimis√© pour les configurations modernes|Utilisation sur des syst√®mes SCSI anciens ou lorsque la compatibilit√© est requise|
|**MegaRAID SAS 8708EM2**|Contr√¥leur RAID SAS|Contr√¥leur RAID SAS avec gestion avanc√©e des disques et support pour des configurations RAID complexes.|Support RAID, gestion avanc√©e des disques et de la redondance|Co√ªt plus √©lev√© et complexit√© accrue dans la configuration|Environnements n√©cessitant des configurations RAID avanc√©es|
|**VirtIO SCSI**|Paravirtualis√© SCSI|Contr√¥leur paravirtualis√© optimis√© pour les environnements virtuels sous Linux et Windows.|Tr√®s bonnes performances, faible surcharge, optimis√© pour la virtualisation | N√©cessite l'installation de pilotes sp√©cifiques (VirtIO)   | Machines virtuelles Linux/Windows n√©cessitant une performance √©lev√©e |
|**VirtIO SCSI Single**|Paravirtualis√© SCSI (single)|Version simplifi√©e de VirtIO SCSI, avec un seul disque attach√©. Utilis√© pour une gestion de disques simple.|Moins de surcharge que les contr√¥leurs traditionnels, bon pour des VM avec un seul disque|Moins flexible que VirtIO SCSI si plusieurs disques sont n√©cessaires|Machines virtuelles avec un seul disque virtuel √† hautes performances|
|**VMware PVSCSI**|Contr√¥leur SCSI VMware|Contr√¥leur SCSI optimis√© pour la virtualisation VMware. Utilis√© pour les VMs dans un environnement VMware. | Tr√®s performant dans des environnements VMware, faible surcharge | Moins adapt√© √† d'autres environnements que VMware|Environnements VMware, surtout pour les machines avec des I/O disques √©lev√©s|

Dans le cas pr√©sent, nous utiliserons **VirtIO SCSI Single** qui correspond mieux √† nos besoins.

* * *

<span class="green-text">**QEMU Agent**</span><br/><br/>

L'agent QEMU est un service qui s'ex√©cute dans la machine virtuelle et communique avec Proxmox. Il permet, par exemple, de faire des arr√™ts de machines virtuelles dits ¬´ propres ¬ª et d'obtenir de l'information plus pr√©cise sur la *VM* en question.

<mark>La case en question n'installe pas l'agent.</mark> Elle ne fait que pr√©ciser √† l'hyperviseur si oui ou non la *VM* utilise l'agent qemu. L'installation de l'agent doit se faire une fois le syst√®me d'exploitation install√©.

* * *

<span class="green-text">**TPM**</span><br/><br/>

Le **TPM** est un composant r√©cent que l'on retrouve sur plusieurs cartes m√®res modernes. D'ailleurs, ce composant est devenu obligatoire pour l'installation de Windows 11. Si vous devez vous rafraichir la m√©moire quant au **TPM**, vous pouvez consulter ¬≠[cette section du site.](../../OS/Windows/12-Securite.md#-tpm-trusted-platform-module-20)

Pour la cr√©ation de notre *VM* aujourd'hui, le **TPM** est facultatif.

![OngletSystem](../Assets/03/OngletSystem.png)

#### Onglet Disks

Il existe une panoplie d'options (encore une fois üòÖ) pour la configuration du disque dur. Analysons ces diff√©rents √©l√©ments ensemble:

<span class="green-text">**Colonne de gauche**</span><br/><br/>

D√©j√†, vous pourrez constater qu'√† gauche, on retrouve une colonne o√π vous pouvez ajouter des disques durs. Nous pourrions par exemple cr√©er une *VM* dans laquelle nous d√©sirons configurer un *RAID*. Dans ce cas, nous aurions besoin de plusieurs disques durs. C'est dans cette colonne qu'il nous faudrait les ajouter.

* * *

<span class="green-text">**Bus/Device**</span><br/><br/>

C‚Äôest ici que nous choisissons le type de bus virtuel auquel notre disque est attach√©. C‚Äôest ce que le syst√®me invit√© verra comme interface de disque. Quelques options sont disponibles:

- **IDE:** tr√®s compatible, mais tr√®s lent. √Ä √©viter sauf si vraiment n√©cessaire.
- **SATA:** meilleure compatibilit√© que IDE, un peu plus rapide.
- **SCSI:** tr√®s performant, moderne, supporte le hotplug, les snapshots et TRIM (avec l‚Äôagent).
- **VirtIO:** interface para-virtualis√©e ultra-performante, n√©cessite des pilotes VirtIO dans l‚ÄôOS invit√©.

Comme nous avons s√©lectionn√© un contr√¥leur de disque **VirtIO SCSI Single** √† la fen√™tre pr√©c√©dente, il serait tout simplement logique d'utiliser un bus SCSI. D'ailleurs, lorsque vous le s√©lectionnerez, Proxmox fera imm√©diatement l'association avec votre contr√¥leur.

* * *
<span class="green-text">**Storage, Disk Size & Format**</span><br/><br/>

Il s'agit ni plus ni moins du stockage sur lequel le disque dur de notre *VM* sera cr√©√©. Il peut s'agir de disques locaux (comme dans notre cas), ou distants (Ceph, NFS, ZFS, etc.)

L'option *Disk Size*, quant √† elle, vous aurez √©videmment compris qu'il s'agit de l'espace maximal que l'on d√©sire allouer √† la machine virtuelle.

Finalement, le format du disque (*gris√© dans notre cas*), permet de s√©lectionner deux formats de disques distincts:

- **RAW:** Plus rapide, mais ne supporte pas les snapshots de plus haut niveau.
- **qcow2:** Supporte les snapshots de haut niveau, mais un peu moins rapide.

> *Oui, mais Gabriel, est-ce qu'on va pouvoir faire des snapshots avec cette machine ?*
>
> *-Les √©tudiants*

**OUI!**, mais proxmox en fera la gestion diff√©remment. Il fera des *snapshots* de type **LVM-Thin**. Ce sont des snapshots de plus bas niveau. Ils ne peuvent pas √™tre compress√©s ou m√™me renomm√©s. Le format du disque dur est gris√©, car nous stockons le disque dur de la *VM* sur un stockage de type *LVM*. Lorsque nous faisons cela, nous sommes contraints d'utiliser le format **RAW**.

* * *

<span class="green-text">**Cache, Discard & IO thread**</span><br/><br/>

La m√©moire cache est une m√©moire temporaire situ√©e en le syst√®me d'exploitation et le disque dur. Son objectif est d'am√©liorer la vitesse de lecture et d'√©criture sur le disque dur. Cela dit, elle peut aussi poser un risque suppl√©mentaire dans la perte de donn√©es involontaire. Dans Proxmox, voici comment se traduisent les options de cache:

- **No Cache:**
    - **Cache h√¥te (proxmox):** D√©sactiv√© ‚ùå
    - **Cache disque physique:** Activ√© ‚úÖ
    - **Performance:** Bonne üôÇ
    - **S√©curit√©:** Moyenne üòê
    - **Description:** Ce mode d√©sactive le cache c√¥t√© h√¥te (le syst√®me Proxmox), mais laisse actif le cache du disque physique. Cela permet une bonne performance tout en r√©duisant les risques de corruption en cas de panne. C‚Äôest le mode par d√©faut depuis Proxmox 2.x.

- **Direct Sync:**
    - **Cache h√¥te (proxmox):** D√©sactiv√© ‚ùå
    - **Cache disque physique:** D√©sactiv√© ‚ùå
    - **Performance:** Faible üòí
    - **S√©curit√©:** Tr√®s √©lev√©e üòÉ
    - **Description:** Le plus s√ªr, mais aussi **le plus lent.** Chaque √©criture est directement synchronis√©e sur le disque physique sans passer par aucun cache. Id√©al pour les environnements critiques o√π la **perte de donn√©es est inacceptable**, mais d√©conseill√©e si la performance est une priorit√©.

- **Write Through:**
    - **Cache h√¥te (proxmox):** Activ√© (lecture uniquement) ‚úÖ
    - **Cache disque physique:** D√©sactiv√© ‚ùå
    - **Performance:** Moyenne üòê
    - **S√©curit√©:** √âlev√©e üòÄ
    - **Description:** Les lectures b√©n√©ficient du cache h√¥te, mais chaque √©criture est imm√©diatement synchronis√©e sur le disque. Cela garantit que les donn√©es sont bien √©crites, tout en offrant une lecture plus rapide. Un bon compromis entre s√©curit√© et performance.


- **Write Back:**
    - **Cache h√¥te (proxmox):** Activ√© ‚úÖ
    - **Cache disque physique:** Activ√© ‚úÖ
    - **Performance:** √âlev√©e üòÄ
    - **S√©curit√©:** Moyenne √† faible üòí
    - **Description:** Les √©critures sont d‚Äôabord stock√©es dans le cache, puis √©crites sur le disque plus tard. Cela am√©liore fortement les performances, **mais en cas de coupure de courant**, les donn√©es non encore √©crites peuvent √™tre **perdues.** Ce mode est acceptable si vous avez un **onduleur (UPS) ou un contr√¥leur RAID avec batterie (BBU)**.

- **Write Back (unsafe):**
    - **Cache h√¥te (proxmox):** Activ√© ‚úÖ
    - **Cache disque physique:** Activ√© ‚úÖ
    - **Performance:** Tr√®s √©lev√©e üòÉ
    - **S√©curit√©:** Tr√®s faible üò≠
    - **Description:** Identique √† Write Back, mais **ne force pas les flushs** (vidage du cache). Cela signifie que les donn√©es peuvent rester longtemps en m√©moire avant d‚Äô√™tre √©crites. C‚Äôest le mode **le plus rapide**, mais aussi **le plus risqu√©**. √Ä √©viter sauf pour des tests ou des environnements non critiques.

Pour notre machine virtuelle, il n'y a pas vraiment de cons√©quence peu importe le choix que vous ferez. En ce qui me concerne, je vais laisser le choix par d√©faut: **No cache**.


L'option `Discard` permet au syst√®me d'exploitation invit√© (Windows ici) de <u>lib√©rer de l'espace disque inutilis√©</u>. On appelle cette technique d'optimisation de l'espace: *Trim*. Cela r√©duit l'espace effective utilis√©e par la machine dans l'hyperviseur. Cette option est recommand√©e si vous d√©sirez √©conomiser de l'espace disque.

L'option **IO Thread** permet d'activer un *thread* d√©di√©e pour chaque disque ou groupe de disques. √Ä titre d'information, un *thread* est une t√¢che au sein d'un service. Voici ce que cette option peut avoir comme impact:

**Sans IO Thread:**
- Tous les acc√®s disque de la VM passent par le **m√™me thread principal** que le reste de la virtualisation.
- Cela peut cr√©er un **goulot d‚Äô√©tranglement**, surtout sur les VMs avec beaucoup d‚Äôactivit√© disque.

**Avec IO Thread activ√©:**
- Chaque disque (ou groupe de disques) peut avoir son propre thread d‚Äôentr√©es/sorties.
- Les acc√®s sont g√©r√©s **ind√©pendamment du reste de la VM**, ce qui <u>r√©duit la latence, augmente les performances et am√©liore la r√©activit√©.</u>

* * *

<span class="green-text">**SSD Emulation, Read-Only, Backup, Replication & Async IO**</span><br/><br/>

L'option `SSD Emulation` pr√©sentera votre disque dur comme un SSD au syst√®me d'exploitation invit√©. Cela peut permettre au syst√®me d'exploitation d'ajuster certains de ses comportements (optimisation, alignement, *trim*, etc.). Cette option est recommand√©e si le stockage r√©el est effectivement un SSD. Ce n'est pas notre cas ici.

L'option `Read-only` permet de monter votre disque dur en lecture seule. Ce n'est utile que lorsque vous effectuez du d√©bogage ou des tests.

L'option `Backup` permet d'inclure automatiquement ce disque dur dans les sauvegardes automatiques de Proxmox. C'est une option int√©ressante si vous d√©sirez prot√©ger vos donn√©es.

`Skip replication` permet d'ignorer la r√©plication de ce disque dur dans le cas o√π vous auriez un cluster, donc plusieurs n≈ìuds Proxmox. Ce n'est pas notre cas ici. Cette option n'aura donc aucune incidence pour le moment.

L'option `Async IO` est tr√®s technique, mais elle peut avoir une incidence sur les performances. Cette option d√©crit les m√©canismes d'acc√®s aux disques durs virtuels. Les syst√®mes d'exploitation modernes supportent le mode *io_uring*. Pour les syst√®mes un peu plus vieux, vous pouvez utiliser l'option *threads* pour assurer une compatibilit√©.

![OngletDisks](../Assets/03/OngletDisks.png)

#### Onglet CPU

Allons-y maintenant avec la configuration du CPU. Si, comme moi, vous avez coch√© la case *Advanced*, vous serez √† m√™me de constater plusieurs options ici aussi.

- **Sockets / Cores**
    - **Sockets:** nombre de processeurs virtuels simul√©s (√âquivalent de CPU physiques pour la VM).
    - **Cores:** nombre de c≈ìurs par processeur physique.

:::caution
Respecter les ressources physiques que vous avez √† votre disposition!
:::

- **Type:** D√©finit le mod√®le de CPU virtuel expos√© √† la *VM*. M√™me si cette option peut paraitre simpliste, elle peut avoir un impact important. Je vous recommande d'utiliser le processeur fourni par d√©faut, car ce dernier sera facilement compatible et migrable vers un autre serveur Proxmox. Si vous avez besoin de plus de performances, vous pouvez utiliser le type `host`. Dans ce cas, Proxmox utilisera le mod√®le physique de votre CPU. Cela r√©duit le besoin d'√©mulation et l'√©limine parfois compl√®tement.

- **VCPUs:** Nombre d'unit√©s de traitement virtuelles allou√©es √† la *VM*. G√©n√©ralement √©gal au nombre de c≈ìurs, mais peut √™tre ajust√© pour limiter l'utilisation du CPU.

- **CPU Limit:** Permet de restreindre la puissance CPU maximale que la VM peut utiliser. Peut √©viter qu‚Äôune VM monopolise le CPU, mais r√©duit la performance.

- **Enable NUMA:** Active la topologie NUMA (Non-Uniform Memory Access). Am√©liore la performance sur les serveurs multisocket. √Ä consid√©rer pour les *VMs* gourmandes en ressources.

- **CPU Affinity:** - Permet de lier la VM √† des c≈ìurs sp√©cifiques du CPU physique. Peut am√©liorer la performance ou l‚Äôisolation dans des cas sp√©cifiques.

- **Extra CPU Flags:** Ces options permettent d‚Äôactiver/d√©sactiver des mitigations de vuln√©rabilit√©s CPU.

![OngletCPU](../Assets/03/OngletCPU.png)

#### Onglet Memory

Dans l'onglet m√©moire, vous pourrez √©videmment octroyer une quantit√© de m√©moire √† votre machine virtuelle. Cela dit, il est int√©ressant de constater les deux champs distincts:

- **Memory:** C'est la quantit√© de m√©moire que vous d√©sirez donner √† la machine, tout simplement.

- **Minimum Memory**: C'est la quantit√© de m√©moire minimale que l'hyperviseur garantira √† la machine en cas de *ballooning*.

Cela nous permet donc de surapprovisionner la RAM. Lorsque vous avez cr√©√© votre serveur Proxmox, vous avez configur√© 16Go de RAM. Nous allons donc en allouer 8Go √† Windows, **MAIS** nous allons utiliser le *balloning* pour faire des √©conomies. Dans le champ `Memory`, inscrivez donc 8192. Puis, dans le champ `Minimum memory`. inscrivez 4096.

Le champ, `Shares` quant √† lui, d√©termine les priorit√©s des *VMs* par rapport au *ballooning*.

Par exemple:

|VM|Memory Max|Memory Min|Shares|
|--|----------|----------|------|
|VM1|4096 MB|1024 MB|100|
|VM2|4096 MB|1024 MB|200|
|VM3|4096 MB|1024 MB|50|

Si l'h√¥te (proxmox), venait √† manquer de RAM, **VM3** serait la premi√®re *VM* √† voir sans m√©moire r√©duite.

![OngletMemory](../Assets/03/OngletMemory.png)

#### Onglet Network

Vous l'aurez compris. C'est ici que vous pourrez d√©terminer comment votre machine virtuelle se branchera au r√©seau. Pour l'instant vous n'avez qu'une seule possibilit√©, et il s'agit de `vmbr0`, le *bridge* par d√©faut, qui est l'√©quivalent d'une connexion par pont dans VMware Workstation.

Choisissez le mod√®le de carte paravirtualis√©e, car nous installerons les pilotes n√©cessaires. √âvidemment, inutile de sp√©cifier un *VLAN*, nous n'en avons pas. La MAC de cette carte r√©seau sera g√©n√©r√©e automatiquement, mais sachez que vous pourriez en sp√©cifier une pr√©cise.

Laissez √©galement les options avanc√©es dans leur √©tat par d√©faut. Tout un volet du cours sera d√©di√© √† la r√©seautique sous Proxmox, c'est pourquoi je ne vous pr√©sente pas tous les d√©tails ici.

![OngletNetwork](../Assets/03/OngletNetwork.png)

#### Onglet Confirm

ENFIN! Nous y voil√†. R√©visez vos param√®tres et confirmez la cr√©ation de votre machine virtuelle en cliquant sur `Finish`.

![OngletConfirm](../Assets/03/OngletConfirm.png)

### √âtape 3 - Installation Windows

Allez, lancez votre installation Windows! J'imagine qu'en session 5, vous ne devriez pas avoir besoin que je vous guide pas √† pas pour installer Windows *right*?...*right?*.......*right*? üòâüòâüòâ

*psssst:* On n‚Äôaurait pas ajout√© un fichier *iso* contenant des pilotes durant la cr√©ation de la *VM* nous ? ü§î

:::caution[R√©seau instable sous Windows]
Durant la cr√©ation des exercices pour ce cours, j'ai rencontr√© des difficult√©s avec la carte r√©seau paravirtualis√© configur√©e pour Windows. Une minute j'avais un acc√®s internet, puis l'autre minute pas d'acc√®s. C'√©tait tr√®s instable. En faisant mes recherches sur le web, j'ai d√©couvert que certains param√®tres avanc√©s de Windows quant aux p√©riph√©riques r√©seau pouvaient nuire √† la bonne fonctionnalit√© de la paravirtualisation.

Si vous avez, vous aussi, de la difficult√© √† avoir un r√©seau stable avec la carte paravirtualis√©, voici ce que vous pouvez entreprendre comme actions pour r√©gler la situation:
- Ouvrez le gestionnaire de p√©riph√©riques dans la *VM* Windows.
- Faites un clic √† l'aide du bouton de droite sur la carte r√©seau *Red Hat VirtIO Ethernet Adapter*
- S√©lectionnez **propri√©t√©s** puis allez dans l'onglet **avanc√©**.
- Modifiez les propri√©t√©s suivantes:
    - *Large Send Offload V2 (IPv4)*: **Disabled**
    - *IPv4 Checksum Offload*: **Disabled**
    - *Offload.Rx.Checksum*: **Disabled**
    - *Offload.Tx.Checksum*: **Disabled**
    - *TCP Checksum Offload (IPv4)*: **Disabled**
    - *UDP Checksum Offload (IPv4)*: **Disabled**

Une fois ces modifications apport√©es, vous devriez retrouver une meilleure stabilit√© du r√©seau.
:::