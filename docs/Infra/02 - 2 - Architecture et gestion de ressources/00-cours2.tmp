import useBaseUrl from '@docusaurus/useBaseUrl';
import ThemedImage from '@theme/ThemedImage';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Cours 2

## Architecture mat√©rielle/logicielle d'un hyperviseur et gestion des ressources üèóÔ∏è

Dans ce deuxi√®me cours, nous ouvrons le capot des hyperviseurs et analysons leur fonctionnement. Jusqu'√† aujourd'hui, dans vos diff√©rents cours, vous avez exploit√© une panoplie de technologies li√©es √† la virtualisation pour faire tourner des serveurs et des postes de travail enti√®rement virtualis√©s. Cela dit, qu'est-ce qui se passe en coulisses ? Comment l'hyperviseur fait la gestion de toutes les ressources √† sa disposition et comment il priorise ses diff√©rentes charges de travail ?

Nous faisons donc un premier tour d'horizon des diff√©rentes technologies pr√©sentent dans les hyperviseurs. **<u>Nul besoin de tout retenir par coeur</u>**, nous reparlerons de tout ces √©l√©ments un √† un au fur et √† mesure que la session avancera.

### D√©finition et r√¥le de l'hyperviseur

Un **hyperviseur** est une couche logicielle qui s'intercale entre le mat√©riel physique et les machines virtuelles. Son r√¥le est de:

- Faire abstraction des ressources mat√©rielles
- Isoler les machines virtuelles les unes des autres
- Prioriser l'acc√®s aux ressources partag√©es
- Maintenir la s√©curit√© et la stabilit√© du syst√®me

### 1. Types d'hyperviseurs

#### 1.1 Hyperviseur de type 1 (Bare Metal)

- S'ex√©cute directement sur le mat√©riel
- Poss√®de un contr√¥le absolu sur les ressources
- Performances optimis√©es pour la virtualisation

**Exemples:** VMware vSphere/ESXi, Microsoft Hyper-V, Citrix XenServer, KVM, etc.

**Architecture:**

<div style={{textAlign: 'center'}}>
    <ThemedImage
        alt="Sch√©ma"
        sources={{
            light: useBaseUrl('/img/Virtu/Hyperviseur_Type1_W.svg'),
            dark: useBaseUrl('/img/Virtu/Hyperviseur_Type1_D.svg'),
        }}
    />
</div>

#### 1.2 Hyperviseur de type 2 (Hosted)

- S'ex√©cute sur un OS h√¥te existant (Windows, Ubuntu, etc.)
- D√©pend de l'OS h√¥te pour l'acc√®s au mat√©riel
- Plus facile √† d√©ployer mais moins performant

**Exemples:** VMware Workstation, VirtualBox, Parallels Desktop, etc.

**Architecture:**

<div style={{textAlign: 'center'}}>
    <ThemedImage
        alt="Sch√©ma"
        sources={{
            light: useBaseUrl('/img/Virtu/Hyperviseur_Type2_W.svg'),
            dark: useBaseUrl('/img/Virtu/Hyperviseur_Type2_D.svg'),
        }}
    />
</div>

### 2. Composants architecturaux cl√©s

#### 2.1 Le Kernel de l'hyperviseur (Noyau central)

Le kernel de l'hyperviseur est le coeur du syst√®me de virtualisation. Il s'ex√©cute en mode privil√©gi√© et coordonne toutes les ressources mat√©rielles, un peu comme un chef d'orchestre qui dirige plusieurs musiciens simultan√©ment. üé∂

#### 2.2 Scheduler (ordonnanceur de vCPUs)

Le scheduler d√©termine quels processeurs virtuels (vCPUs) s'ex√©cutent sur quels coeurs physiques et √† quel moment. L'objectif est d'optimiser l'utilisation des coeurs physiques. 

Imaginez un professeur qui doit faire passer un examen √† 100 √©tudiants et qui n'a que 3 salles d'examen √† sa disposition. Le professeur devra alors s'organiser pour optimiser au maximum l'utilisation de ses salles d'examen en d√©terminant quel √©tudiant passera son examen dans quelle salle et √† quelle heure.

D'un point de vue plus technique, le *scheduler*:

- Maintient des **files d'attente** des vCPUs pr√™ts √† s'ex√©cuter.
- Applique des **algorithmes d'ordonnancement** (*round-robin*, gestion de priorit√©s, *fair-share*)
- G√®re les tranches de temps allou√©es.
- Surveille les **m√©triques de performance** pour optimiser les r√©partition

L'hyperviseur peut faire appel √† plusieurs techniques pour s'assurer que les *VMs* aient un acc√®s aux processeurs physiques:

| Algorithme|Principe|Exemple pratique|Avantages|Inconv√©nients|Cas d‚Äôusage id√©al|
|-----------|------------------|---------------------|--------------------|------------------------------|--------------------------------------|
|**Round Robin**|Chaque VM re√ßoit une tranche de temps CPU √©gale, puis passe la main| C≈ìur 1 : VM1 (10‚ÄØms) ‚Üí VM2 (10‚ÄØms) ‚Üí VM3 (10‚ÄØms) ‚Üí VM1‚Ä¶|√âquitable pour tous|Ne s‚Äôadapte pas aux besoins r√©els|Environnements homog√®nes, tests simples|
|**Priority-based**|Les VMs sont servies selon leur priorit√© d√©finie| VM-DB : HIGH (50‚ÄØ%) ; VM-Web : MEDIUM (30‚ÄØ%) ; VM-Test : LOW (20‚ÄØ%)|Garantit les ressources aux charges critiques|Les faibles priorit√©s peuvent √™tre ralenties|Production avec charges critiques identifi√©es|
|**Fair Share**|Allocation proportionnelle ajust√©e selon l‚Äôutilisation r√©elle|Si VM1 utilise peu, VM2 et VM3 r√©cup√®rent le surplus|Optimise l‚Äôutilisation globale des ressources|Plus complexe √† mettre en ≈ìuvre|Workloads variables|

#### 2.3 Gestionnaire de m√©moire (*Memory Manager*)

Le memory manager g√®re la m√©moire RAM comme un biblioth√©caire tr√®s organis√© qui sait exactement o√π placer chaque livre et comment les retrouver rapidement.

D'un oeil plus technique:

- Il maintient la table de correspondance (*mapping tables*) entre les adresses de la m√©moire virtuelle utilis√©es par les *VMs* et les adresses physiques r√©elles de l'h√¥te (m√©moire physique).

    ```yaml
    Mapping m√©moire simplifi√© :

    VM1 demande adresse 0x1000 ‚Üí Memory Manager traduit ‚Üí Adresse physique 0x5A000
    VM2 demande adresse 0x1000 ‚Üí Memory Manager traduit ‚Üí Adresse physique 0x7B000

    Chaque VM pense avoir sa propre m√©moire, mais tout est g√©r√© centralement

    ```
- Il optimise la m√©moire √† l'aide de diff√©rentes techniques üëá

    |Technique|Principe (analogie)|Fonctionnement technique  cl√©|Avantages|Inconv√©nients / Risques|
    |---------|-------------------|-----------------------------|---------|-----------------------|
    |**Memory Ballooning** (Gonflage m√©moire)|Lib√©rer des places de parking pour d‚Äôautres invit√©s|Driver balloon dans la VM alloue de la m√©moire ¬´‚ÄØfactice‚ÄØ¬ª ‚Üí OS invit√© croit qu‚Äôelle est utilis√©e ‚Üí Hyperviseur r√©cup√®re la RAM physique et la r√©attribue|- Redistribution dynamique de la RAM<br/>- √âvite le swap<br/>- Transparent pour les applis |- Peut d√©grader les performances de la VM ¬´‚ÄØgonfl√©e‚ÄØ¬ª<br/>- D√©pend du support du driver    |
    |**Memory Compression** (Compression m√©moire)|Ranger ses affaires en optimisant l'espace au maximum|Pages peu utilis√©es compress√©es en RAM (LZ4 rapide, ZSTD efficace) ‚Üí D√©compression √† l‚Äôacc√®s| - R√©duit la pression m√©moire<br/>- 150√ó plus rapide que le swap SSD| - Plus lent que RAM native (√ó3)<br/>- Consomme du CPU pour compresser/d√©compresser|
    |**Transparent Page Sharing** (TPS)|Partager une photocopieuse pour √©viter les doublons| D√©tection de pages identiques (hash + v√©rif byte-√†-byte) ‚Üí Une seule copie physique ‚Üí Copy-on-Write si modifi√©e| - √âconomie m√©moire massive (jusqu‚Äô√† 75‚ÄØ%)<br/>- Id√©al pour VMs identiques| - Risque de canal auxiliaire (side-channel attack)<br/>- Souvent d√©sactiv√© par d√©faut|

- Il g√®re le *swap* (extension de la m√©moire sur disque) quand la RAM est insuffisante.
- Surveille l'**utilisation m√©moire** en temps r√©el.


#### 2.4 Pile d'entr√©e/sortie virtualis√©e (*I/O stack*)

L'I/O Stack intercepte et g√®re toutes les demandes d'acc√®s aux p√©riph√©riques (r√©seau, disque, USB). On pourrait le comparer √† un service de messagerie qui achemine tous les courriers entre les appartements d'un immeuble et l'ext√©rieur.

M√©canismes techniques:

- **Interception** des instructions d'I/O via les *VM exits*
- **Translation** des requ√™tes virtuelles vers le mat√©riel physique
- **QOS (Quality Of Service)**: Priorisation et limitation des d√©bits
- **Mise en file d'attente** et optimisation des acc√®s

```yaml
Flux d'une requ√™te r√©seau :

VM: "Je veux envoyer un paquet r√©seau"
    ‚Üì (VM exit - interruption)

I/O Stack: "Je traduis et route vers la carte r√©seau physique"
    ‚Üì (transmission)

Carte r√©seau: "Paquet envoy√© sur le r√©seau"
```

#### 2.5 Module de s√©curit√© (*Security Module*)

Le module de s√©curit√© assure l'isolation entre les *VMs*. On pourrait le comparer √† un syst√®me de s√©curit√© d'immeuble qui garantit que chaque locataire reste dans son appartement.

Fonctions techniques:
- **Isolation de la m√©moire:** emp√™che les *VMs* d'acc√©der √† la m√©moire des autres.
- **Contr√¥le des privil√®ges:** validation des instructions sensibles.
- **IOMMU (Input-Output Memory Management Unit):** isolation de l'acc√®s aux diff√©rents p√©riph√©riques physiques.
- **Audit et Logging:** tra√ßabilit√© des √©v√©nements

#### 2.6 Carte r√©seau virtuelle

Chaque *VM* voit une carte r√©seau qui lui semble bien r√©elle, mais c'est en fait une interface logicielle qui traduit ses demandes. L'impl√©mentation de cette carte r√©seau virtuelle peut se faire de diff√©rentes fa√ßons:

- **√âmulation compl√®te:** La *VM* n'y voit que du feu et pense qu'elle poss√®de une carte r√©seau Intel e1000 ¬´ classique ¬ª
- **Paravirtualisation:** Pilote optimis√© (virtio-net). Contrairement √† l'√©mulation compl√®te, ce pilote ¬´ *sait* ¬ª qu'il a affaire avec une carte r√©seau virtuelle et adapte son comportement. Ainsi, la traduction est moins lourde qu'avec l'√©mulation et les performances s'en trouvent grandemment am√©lior√©es.
- **SR-IOV:** Un acc√®s direct √† une portion de la carte r√©seau physique.

Nous reviendrons plus en profondeur sur la virtualisation des r√©seaux ult√©rieurement dans la session.

#### 2.7 Contr√¥leur de stockage virtuel

Le contr√¥leur de stockage virtuel fait croire √† chaque *VM* qu'elle a son propre disque dur, alors qu'en r√©alit√© tout est stock√© dans des fichiers ou partag√© sur un SAN. Le contr√¥leur peut:

- **√âmuler** des contr√¥leurs SCSI, SATA ou NVMe standards
- **Traduire** directement les commandes destin√©es au stockage (Ex: lire secteur 1000 --¬≠¬≠> lire offset 512KB dans vm1.vmdk)
- **G√®re** et **optimise** l'utilisation de m√©moire cache
- **Offre** la possibilit√© de faire des *snapshots*

Lorsqu'on aborde le stockage en virtualisation, deux √©l√©ments cl√©s d√©finissement celui-ci : Le *type de stockage* et *l'approvisionnement*. Le type de stockage repr√©sente la mani√®re avec laquelle nous conserveront les donn√©es des machines virtuelles.

| Type de stockage | Description | Avantages | Inconv√©nients | Cas d‚Äôusage typiques |
|------------------|-------------|-----------|---------------|----------------------|
| **Fichiers disques virtuels** (.vmdk, .vhd/.vhdx, .qcow2, .raw) | Chaque disque virtuel est un fichier sur le syst√®me de fichiers de l‚Äôh√¥te. | - Facile √† g√©rer et d√©placer<br/>- Snapshots simples<br/>- Compatibilit√© large | - L√©g√®re perte de performance par rapport au direct<br/>- D√©pend du FS h√¥te | Environnements flexibles, lab, snapshots fr√©quents |
| **LUNs directs (SAN)** | Volume logique sur baie SAN pr√©sent√© directement √† la VM. | - Performance native<br/>- Pas d‚Äôoverhead fichier | - Moins flexible<br/>- Snapshots plus complexes | Bases de donn√©es, workloads critiques |
| **Stockage distribu√©** (vSAN, Ceph, GlusterFS) | Pool de stockage partag√© entre plusieurs serveurs, avec r√©plication et tol√©rance aux pannes. | - Haute dispo<br/>- Scalabilit√©<br/>- R√©plication automatique | - Complexit√© de mise en place<br/>- Besoin r√©seau performant | Cloud priv√©, clusters haute dispo |

Quant √† l'approvisionnement, il s'agit de la m√©thode avec laquelle nous attribuons l'espace disque.

| Type d‚Äôapprovisionnement | Description | Avantages | Inconv√©nients | Cas d‚Äôusage typiques |
|--------------------------|-------------|-----------|---------------|----------------------|
| **Thick Provisioning** (allocation compl√®te) | L‚Äôespace total est r√©serv√© d√®s la cr√©ation du disque virtuel. | - Performance constante<br/>- Espace garanti<br/>- Pas de fragmentation | - Gaspillage initial si peu utilis√©<br/>- Cr√©ation plus lente | Production critique, stockage abondant |
| **Thin Provisioning** (allocation dynamique) | L‚Äôespace est allou√© au fur et √† mesure de l‚Äôutilisation r√©elle. | - √âconomie d‚Äôespace<br/>- Cr√©ation rapide<br/>- Overcommit possible | - Perf variable<br/>- Risque de ‚Äúdisk full‚Äù impr√©vu<br/>- Surveillance n√©cessaire | Cloud mutualis√©, environnements dynamiques |


#### 2.8 Carte graphique virtuelle

Vous l'aurez sans doute compris, c'est elle qui assurera l'affichage des *VMs*, depuis ka console de texte jusqu'√† l'acc√©l√©ration 3D pour les jeux. Un peu comme avec la carte r√©seau virtuelle, il existe trois niveau de virtualisation pour l'affichage:

|Niveau|Description|Cas d'usage|Performance|
|------|-----------|-----------|-----------|
|**√âmulation VGA Basique**|L'hyperviseur simule une carte VGA standard, suffisante pour l'affichage console et le d√©marrage|Installation d'OS, d√©pannage, affichage minimal.|Faible (pas d'acc√©l√©ration mat√©rielle)|
|**2D/3D acc√©l√©r√©e**|Utilisation de pilotes virtuels optimis√©s (ex. VMware SVGA, virtio-gpu) avec support d‚ÄôAPI comme OpenGL.|Applications graphiques, bureautique, rendu 3D l√©ger.|Moyenne √† √©lev√©e selon l‚Äôimpl√©mentation.|
|**GPU Passthrough**|La VM acc√®de directement √† une carte graphique physique d√©di√©e via des technologies comme IOMMU.|Jeux vid√©o, calcul GPU, rendu 3D intensif.|Native (quasi identique √† un usage hors VM).|

#### 2.9 Console de gestion

La console de gestion est ni plus ni moins votre *cockpit* pour visualiser et contr√¥ler l'infrastructure virtualis√©e. Vous y retrouverez:

- **Tableau de bord en temps r√©el:** m√©triques CPU, m√©moire, stockage, r√©seau
- **Wizards de configuration:** assistants pour cr√©er et configurer vos *VMs*
- **Gestion des templates:** mod√®les pr√©-configur√©s pour d√©ploiment rapide
- **Contr√¥le des permissions:** qui peut faire quoi sur quelle ressource

*Console de gestion de proxmox* üëá

![ConsoleProxmox](../Assets/02/ProxmoxGUI.png)

*Console de gestion de VMware vSphere* üëá

![ConsolevSphere](../Assets/02/vSphereGUI.png)

#### 2.10 Monitoring et m√©triques

Le syst√®me de *monitoring* collecte en permanence des donn√©es sur le fonctionnement de l'infrastructure.

Type de donn√©es collect√©es:

- **M√©triques performance :** % CPU, GB RAM utilis√©s, IO disque, R√©seau
- **√âv√©nements syst√®me :** d√©marrage/arr√™t VMs, migrations, pannes
- **Logs applicatifs :** messages d'erreur, warnings, informations de debug
- **Seuils et alertes :** notifications automatiques quand quelque chose d√©passe les limites

